# Training Configuration for Trash Detection System
# Dataset: Roboflow Garbage Classification 3 - BALANCED
# Train: 6,083 images | Valid: 1,573 images | Test: 1,042 images
# Target: mAP50 >= 0.75, Precision >= 0.80, Recall >= 0.70

# Detection Model Configuration
detection:
  # Model settings - YOLOv8-Large cho accuracy cao
  model_name: "yolov8l.pt"
  pretrained: true
  
  # Dataset - BALANCED VERSION
  data_yaml: "data/garbage_detection_balanced/data.yaml"
  
  # --- Training settings ---
  epochs: 300
  batch_size: 4           # Batch nhỏ cho model lớn
  imgsz: 640              
  device: "auto"
  workers: 8
  patience: 80            # Early stopping patience cao
  save_period: 25

  # --- Optimizer & LR (FINE-TUNED) ---
  optimizer: "SGD"
  lr0: 0.01
  lrf: 0.001
  weight_decay: 0.0005
  momentum: 0.937
  warmup_epochs: 5.0
  warmup_momentum: 0.8
  warmup_bias_lr: 0.1
  nbs: 64

  # --- Detection settings ---
  conf: 0.001
  iou: 0.7
  max_det: 300

  # --- Loss weights ---
  cls: 1.0                # Class loss cao cho balanced dataset
  box: 7.5
  dfl: 1.5

  # --- Augmentations ---
  hsv_h: 0.02
  hsv_s: 0.8
  hsv_v: 0.5
  degrees: 20.0
  translate: 0.15
  scale: 0.9
  shear: 3.0
  perspective: 0.0005
  flipud: 0.5
  fliplr: 0.5
  mosaic: 1.0
  mixup: 0.2
  copy_paste: 0.2
  close_mosaic: 30
  erasing: 0.4

  # --- Output ---
  project: "runs/train"
  name: "garbage_detection_v3_balanced"
  exist_ok: true
  project_name: "trash_detection"
  experiment_name: "garbage_detection_v3"
  save_dir: "results/detection"

# Classification Model Configuration  
classification:
  # Model settings
  model_name: "yolov8n-cls.pt"  # yolov8n-cls, yolov8s-cls, yolov8m-cls
  pretrained: true
  
  # Dataset - sử dụng cùng dataset, tạo từ detection data
  data_yaml: "data/garbage_classification"
  
  # Training hyperparameters
  epochs: 50
  batch_size: 32
  img_size: 224
  learning_rate: 0.001
  weight_decay: 0.0005
  momentum: 0.937
  
  # Augmentations
  hsv_h: 0.015
  hsv_s: 0.7
  hsv_v: 0.4
  degrees: 15.0
  translate: 0.1
  scale: 0.5
  shear: 0.0
  perspective: 0.0
  flipud: 0.0
  fliplr: 0.5
  auto_augment: "randaugment"
  erasing: 0.4
  
  # Training settings
  patience: 20
  save_period: 5
  device: "auto"
  workers: 8
  
  # Optimizer
  optimizer: "AdamW"
  lr_decay: 0.01
  
  # Output
  project_name: "trash_classification"
  experiment_name: "classification_v1"
  save_dir: "results/classification"

# Pipeline Configuration
pipeline:
  # Model paths (will be set after training)
  detection_model_path: "models/detection/best.pt"
  classification_model_path: "models/classification/best.pt"
  
  # Detection settings
  detection_conf_threshold: 0.25
  detection_iou_threshold: 0.45
  detection_img_size: 640
  
  # Classification settings
  classification_img_size: 224
  classification_conf_threshold: 0.5
  
  # Threading settings
  max_workers: 4
  queue_size: 100
  
  # Performance optimization
  skip_classification_below: 0.3  # Skip classification for low-confidence detections
  batch_classification: true
  
  # Output settings
  save_results: true
  show_labels: true
  show_confidence: true
  line_thickness: 2

# Evaluation Configuration
evaluation:
  # Model paths
  detection_model_path: "results/detection/garbage_detection_v1/weights/best.pt"
  classification_model_path: "results/classification/classification_v1/weights/best.pt"
  
  # Dataset paths
  detection_data_yaml: "data/garbage_detection/data.yaml"
  classification_data_yaml: "data/garbage_classification"
  
  # Evaluation settings
  detection_conf_thresholds: [0.1, 0.25, 0.5, 0.75]
  detection_iou_threshold: 0.5
  classification_conf_threshold: 0.5
  
  # Output
  results_dir: "results/evaluation"
  experiment_name: "evaluation_v1"
  
  # Visualization
  save_plots: true
  show_plots: false

# Dataset Configuration
datasets:
  # TACO Dataset (Detection)
  taco:
    download_url: "http://tacodataset.org/files/TACO.zip"
    base_dir: "/home/huynguyen/source/Trash-Detection/data/raw"
    processed_dir: "/home/huynguyen/source/Trash-Detection/data/processed"
    
    # Class mapping (TACO -> Custom)
    class_mapping:
      # Có thể customize class mapping ở đây
      # VD: "Aluminium foil": "metal"
      
    # Data splits
    train_split: 0.6
    val_split: 0.1
    test_split: 0.3
    
    # Processing settings
    min_bbox_area: 100
    max_bbox_area: 100000
    
  # Garbage Dataset (Classification)
  trashnet:
    download_url: "https://github.com/garythung/trashnet/archive/master.zip"
    base_dir: "/home/huynguyen/source/Trash-Detection/data/raw"
    processed_dir: "/home/huynguyen/source/Trash-Detection/training-model/data/processed/classification"
    
    # Class mapping (TrashNet -> Custom)
    classes: ["cardboard", "glass", "metal", "paper", "plastic", "trash"]
    
    # Data splits
    train_split: 0.6
    val_split: 0.1
    test_split: 0.3
    
    # Processing settings
    img_size: [224, 224]
    quality: 95

# Hardware Configuration
hardware:
  # CPU-optimized settings (GPU not available)
  mixed_precision: false  # Disabled for CPU training
  
  # CPU settings
  num_workers: 4  # Reduced for CPU training
  pin_memory: false  # Disabled for CPU training
  
  # Batch size auto-scaling
  auto_batch_size: false  # Tự động tìm batch size tối ưu
  
# Logging and Monitoring
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  log_file: "training.log"
  
  # Tensorboard/Wandb integration
  use_tensorboard: false
  use_wandb: false
  wandb_project: "trash-detection"
  
  # Progress tracking
  log_frequency: 10  # Log every N epochs
  save_frequency: 20  # Save checkpoint every N epochs

# Paths Configuration
paths:
  # Base directories
  data_dir: "data"
  models_dir: "models" 
  results_dir: "results"
  logs_dir: "logs"
  
  # Pretrained models (sẽ tự động download nếu chưa có)
  pretrained_models:
    detection: "yolov8n.pt"
    classification: "yolov8n-cls.pt"